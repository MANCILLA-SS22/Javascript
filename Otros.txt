estefany
oyuki
salma
gaby
sandra
yolanda
mariana
michelle
yanet
denisse
jennifer
karla
edna
evelin

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$        


                                                                                                                   React

- Componentes (components): Es un conjunto de elementos que cumplen una función específica en la interfaz de usuario. Se utilizan para construir la jerarquía de todos esos elementos. Cada componente puede contener otros componentes como 
  hijos. básicamente, las aplicaciones en React básicamente se construyen mediante los mismos. permiten separar la interfaz de usuario en piezas independientes, reutilizables y pensar en cada pieza de forma aislada.
  
- Propiedades (props): Son la forma que tiene React para pasar parámetros de un componente superior a sus hijos. Se utilizan para pasar datos de un componente padre a un componente hijo, manteniendo el flujo unidireccional 
  de los datos. Las props son objetos que contienen datos específicos que un componente necesita para renderizarse correctamente. Esto permite la reutilización de componentes en diferentes partes de la aplicación con diferentes datos.
  Si alguna prop es una función (callback), el componente hijo puede llamarla para provocar efectos secundarios en el componente padre.
  
- prop.childern: Children es una manera que tiene react de permitirnos proyectar/transcluir uno o más componentes dentro otro. Es ideal cuando necesitamos que un elemento quede dentro de otro, sin que sepan el uno del otro, y cuando   
  necesitamos implementar patrones más complejos.  
  El concepto de children es la forma en que React nos permite incluir un componente dentro de otro sin que al padre le importe exactamente qué componente o componentes hijos están siendo incluidos. Los elementos hijos son aquellos que se 
  colocan dentro de la etiqueta de apertura y cierre del componente y la prop “children” se utiliza para acceder y manipular estos elementos hijos desde dentro del componente padre. 
  De esta manera, podemos crear componentes más flexibles y reutilizables que acepten contenido personalizado y que puedan renderizarlo de manera dinámica. 
    
  La prop children es una prop especial que se pasa a los componentes. Es un objeto que contiene los elementos que envuelve un componente. Por ejemplo, si tenemos un componente Card que muestra una tarjeta con un título y un contenido, 
  podemos usar la prop children para mostrar el contenido:
    
         function Card(props) {
            return (
              <div className="card">
                 <h2>{props.title}</h2>
                 <div>{props.children}</div>
              </div>
            )
         }
         
    Y luego podemos usarlo de la siguiente forma:
    
         <Card title="Título de la tarjeta">
           <p>Contenido de la tarjeta</p>
         </Card>
         
    En este caso, la prop children contiene el elemento <p>Contenido de la tarjeta</p>.
        

- Render: The render method is a vital part of ReactJS, as it determines what gets displayed on the screen. It takes in the app’s state and renders it to a DOM node. This makes it easy to track what’s going on in your app, as the render 
  method will always show the latest state. The render method is called automatically by ReactJS, so you don’t need to call it yourself. However, you can call it manually if you need to. 
  The render method is also where you should do any processing that doesn’t need to happen every time the state changes. 
  For example, if you have an extensive list of items, you might want only to render the part of the list that’s visible on the screen. Your app will be more efficient and won’t slow down as the state changes.
  
    > What Is The Use Of the Render Method in ReactJS? The render method in ReactJS functional component is the default lifecycle method that returns a single child component to be rendered by the parent. It’s important to use this method 
      when you want to return a component from a parent to a child. This will ensure that the child receives the correct data and state from the parent.
    > When Not To Use The Render Method In React Js? There may be times when you don’t want to use the render method. For example, if you’re working with higher-order components, stateless functional components, or memorization there, you 
      may not need to use it. You can simply return whatever value is passed into the return method in these cases.
    > 1) The render method will always return a single child component. 2) The render method sets up the child component’s initial state and lifecycle methods. 3) The render method is used when you want to create a new component. 4) The 
      render method is more common.	

- return: The return method in React is a way to return data from a component. It returns the data that was passed into the component, which the parent component can then use. The return method is generally used when you want to return a 
  single value from a component. For example, if you want to return the text of a button from a Component, you would use the return method.
   
    > When To Use The Return Method In React Js? The return method can be used in a few different situations. One example would be when you want to return a default value from a function. Another instance would be when you wish to return a 
      value from a component used as a stateless functional component. You can also use the return method to return values from higher-order components.
    > When To Not Use The Return Method In React Js? The return method should not be used when you need to return multiple values from a function. In this case, the render method should be used instead. Additionally, the return method should 
      not be used when you need to call a function that is not in the same component. 
    > 1) The return method can return any value. 2) The return method returns a value. 3) The return method is used when you want to reuse an existing component. 4) The return method is less commonly used.
  
- Componentes basados en funciones: Hoy en día todos los componentes de React se crean a partir de funciones, lo que hace que sea mucho más fácil de escribir el código y entenderlo. Antes aquellos componentes que se encargaban del 
  funcionamiento de la app, se creaban a partir de la clase Components para poder implementar las características de los componentes de React. Lo que hacía más complejo el modelo mental.
  Pueden recibir propiedades (props). Tienen la capacidad de hacer render de un único elemento. Aunque este elemento puede tener muchos elementos dentro. Pueden tener estados.
    
- Controlled vs Uncontrolled Components & Stateless vs Stateful Components: 
    
- Render de un único elemento: Los componentes deben retornar un solo elemento o componente, pero este elemento o componente sí puede tener más de un elemento o componente hijo. En caso de no necesitar que el elemento padre forme parte del 
  árbol del DOM, se puede utilizar React.Fragment, o lo que es lo mismo utilizar un tag sin tipo <></>.
  
- Key: En REACT, debemos incluir en cada elemento la propiedad key, que marque la identidad del elemento. Es decir, debemos poner algo que se encuentre en el array u objeto pero que estemos seguros de que NO SE REPETIRA (lo mas recomendable    
  seria el id, ya que este empieza desde 1 hasta un numero indefinido pero que siempre estara cambiando). Esto ayudará a react a optimizar el rendering ante cambios en el array. De no tenerla podemos auto-generarla con el index provisto por 
  el segundo parámetro de map, pero sólo optimizará si hay adiciones al final del array. Whenever the key changes on a component, even if that component is not part of a list, whenever it changes, REACT will destroy the old component 
  instance and create a new one.
   
 
  
- States: Los estados de un componente en React se utilizan para representar la información que puede cambiar durante la vida útil del componente y afectar su representación en la interfaz de usuario. Todo cambio de estado va inicializar el 
  proceso de render a partir del nodo donde se produjo el cambio de estado y así se generará el nuevo Virtual DOM que luego será reconciliado. Los estados son un concepto de React, no de JavaScript, por lo que para implementarlo vamos a 
  necesitar de los Hooks de React.
  
  El estado en React es una de las maneras en las que se procesan datos. Desde el punto de vista de los datos que React puede manejar, tenemos el objeto props, con el que podemos insertar todo tipo de propiedades a un elemento, y tenemos los 
  estados. El estado es un objeto que contiene datos que pueden cambiar en el tiempo. En React, el estado se usa para controlar los cambios en la interfaz. El objeto props nos permite insertar datos estáticos. Con esto nos referimos a que 
  pasamos propiedades a un componente o elemento que luego se renderiza o visualiza de una determinada manera, con base a los datos que le pasamos. Entonces, si necesitamos darle dinamismo a un elemento, es decir, datos que se modifiquen a 
  lo largo del tiempo, necesitaremos utilizar el estado en React.
  
  El estado en React, también conocido como state, es el segundo tipo de dato que maneja esta librería de JavaScript. Mientras que las props son los datos que podemos pasarle a un componente o elemento React desde afuera, un estado se 
  conforma por los datos internos que un componente puede manejar. A medida que estos datos son modificados, ya sea por una interacción del usuario o por una recepción de datos de la API, el estado será modificado. Entonces, cada cambio de 
  ese estado provocará que el elemento o componente se renderice de nuevo con una nueva representación en pantalla.
  
  Ten presente que podemos utilizar un estado en cualquier tipo de componente o elemento, sea del nivel más bajo o el nivel más alto. Allá donde necesitemos datos que cambian a lo largo del tiempo, podemos utilizar un estado.

- Render y efectos: El funcionamiento de React está estrechamente ligado al cambio de estados. Cuando se produce un cambio de estado, React ejecuta un nuevo proceso de renderizado para ese componente y, de manera recursiva, para todos sus 
  componentes hijos. Durante este proceso React ejecuta de nuevo las funciones de los componentes para generar el nuevo árbol de elementos de la interfaz de usuario.  Dentro de los componentes podemos tener funciones para realizar diferentes 
  tareas, como, por ejemplo, una llamada a una api para obtener datos. Si en cada render se ejecuta esta llamada a la API, quiere decir que un cambio de estado está provocando efectos secundarios y no controlarlos puede traernos problemas. 

- side effects: Side effects can be fetching data from a remote server, reading or writing to local storage, setting up event listeners, or setting up a subscription. These side effects can occur when a button is clicked, a form is submitted 
  or when a component is mounted and unmounted. React’s useEffecthook allows functional components to do things when a component is mounted or when some properties or states change. This hook also allows cleaning up when the component is 
  unmounted.

- Hooks: Es una función especial que permite a los desarrolladores utilizar el estado y otras características de React en componentes de función, y utilizar las características de React en los componentes funcionales, en lugar de tener que 
  usar la clase Component. Los hooks son funciones que se pueden usar dentro de los componentes funcionales para agregar funcionalidad adicional de React. Las caracteristicas de los Hooks son:
    1) Comienzan con el prefijo “use” para que React pueda identificarlos y realizar validaciones.
    2) Solamente pueden utilizarse dentro de componentes funcionales.
    3) Deben ejecutarse siempre, es decir, en cada renderizado y el orden de ejecución debe ser siempre el mismo. No puede estar dentro de if, for, etc.
    4) Deben ejecutarse siempre en el cuerpo de la función del componente, por lo que normalmente se los ejecuta al inicio.
    5) Cuando los parametros del hook se quieran recuperar en una funcion a la que fueron mandados, se deben desestructurar. Es decir, poner como el siguiente ejemplo:  function Counter( {conteo, setConteo} ){
    
  Cualquier función que se declare con el prefijo “use”, React la tratará como un hook realizando las validaciones correspondientes y llamará a otros hooks dentro de esta función sin ser esta un componente, ya que si este hook padre cumple 
  las validaciones y, dentro de él, los hooks cumplen los requisitos correspondientes, pasarán todas las validaciones y podrá ejecutarse sin problemas. A estos hooks declarados por el desarrollador para encapsular una lógica de componente 
  específica se les llama custom hooks. Mientras el valor dentro del parentesis de useState no cambie (o se actualice), quiere decir que no se volvera a ejecutar la funcion, no hasta que haya un cambio.
  
  Lo más importante es que los hooks deben ser llamados únicamente en el nivel superior del componente funcional, nunca dentro de bucles, condiciones o funciones anidadas. 
  Esto asegura que los hooks siempre sean llamados en el mismo orden en cada renderizado y mantener la relación con cada una de las fibras de React. 
  También es importante tener en cuenta que los hooks no deben ser llamados desde funciones regulares. Si se llama a un hook desde una función regular, se producirá un error en tiempo de ejecución. 
  React detecta que una función es un componente gracias a la convención PascalCase utilizada para nombrarlos.
      
    > Hooks de estado: El estado permite que un componente «recuerde» información como la entrada de un usuario. Por ejemplo, un componente de formulario puede utilizar un estado para guardar la entrada del valor mientras que un componente 
      de galería de imágenes puede utilizar un estado para guardar el índice de la imagen seleccionada.
      
    > Hooks de contexto: El contexto permite a un componente recibir información de padres lejanos sin pasarlas como props. Por ejemplo, el componente en el nivel superior de tu aplicación puede pasar el actual tema de la UI a todos los 
      componentes dentro, sin importar la profundidad dentro del componente.
    
    > Hooks de refs: Las refs le permiten a un componente mantener alguna información que no es utilizada para el renderizado como un nodo del DOM o el ID de un timeout. A diferencia del estado, actualizar una ref no vuelve a renderizar tu 
      componente. Las refs son una «puerta de escape» del paradigma de React. Son útiles cuando necesitas trabajar con sistemas distintos de React, como las APIs integradas del navegador.

    > Hooks de Efecto: El Hook de Efecto permite a un componente conectarse y sincronizarse con sistemas externos. Esto incluye lidiar con la red, el DOM del navegador, animaciones, widgets escritos utilizando una biblioteca de UI diferente 
      y otro código que no es de React.

    > Hooks de rendimiento: Una forma común de optimizar el rendimiento del rerenderizado es evitar trabajo innecesario. Por ejemplo, puedes decirle a React que reutilice un cálculo guardado en caché o que se salte un rerenderizado si los 
      datos no han cambiado desde el renderizado anterior. Para evitar cálculos y renderizados innecesarios, usa uno de estos Hooks:

    > Otros: Algunas veces no podrás evitar un rerenderizado porque la pantalla realmente necesita una actualización. En ese caso, puedes mejorar el rendimiento separando las actualizaciones bloqueantes que deben ser síncronas (como al
      escribir dentro de una entrada de texto) de las actualizaciones no bloqueantes, que no necesitan bloquear la interfaz de usuario (como actualizar un gráfico). Para priorizar el renderizado, puedes usar: useTransition y useDeferredValue
    
    > Custom hooks: Los custom hooks en React son un tipo de función JavaScript que simula el funcionamiento de los hooks en React. Los custom hooks en React son muy útiles siempre que tengamos una lógica que se repite entre varios componen
      En estos casos, podemos sacar esta lógica y aplicarla a un custom hook, es decir, una función que ejecute los pasos que necesitamos de manera automática.
      Al no ser funciones cualquiera, los custom hooks en React deben seguir una serie de reglas para ser considerados hooks y no funciones. A continuación, te explicamos cuáles son.
       ~ El nombre empieza por «use»: La primera regla de los custom hooks en React es que su nombre debe empezar con la palabra use. Esta convención se crea siguiendo los hooks originales de React (useEffect, useState, useRef) y los 
         posteriores hooks en React Router (useParams, useLocation, useNavigate). Se considera que esto es una regla porque la comunidad ha decidido que es más sencillo reconocer un custom hook cuando sigue esta norma. Sin embargo, en teoría 
         podrías crear uno con otro nombre.
       ~ Puede llamar a otros hooks: Lo que realmente tienen de particular los custom hooks en React es que pueden llamar a otros hooks. En este orden de ideas, React considera como custom hook a aquella función que dentro llama a un hook 
         original o a otro custom hook.
       ~ Los custom hooks en React son muy útiles para extraer funcionalidades, hacer refactors y mantener nuestros componentes más simplificados. Esto es especialmente común cuando tenemos componentes que llaman a una API para obtener un 
         dato, lo meten en un estado y ejecutan una acción determinada con él. Todos estos pasos, que al final son muy repetitivos, se simplifican con el uso de custom hooks.
       ~ Cuando creamos un custom hook, este puede ser utilizado en diferentes components. Y si este custom hook tiene un useState, al momento de utilizar dicho hook en 2 o mas diferentes components, los estados de cada componente no se 
         relacionaran los unos con los otros. Es decir, si cambia el estado en un custom hook utilizado en un componente, los estados del otro componente no se veran afectados aunque se utilice el mismo custom hook.

- forwardRef: 

- createPortal: En React, createPortal se utiliza para renderizar un componente o elementos hijos fuera de la jerarquía del DOM del componente padre. Esto es útil en situaciones donde necesitas que un componente se renderice en una parte 
  diferente del DOM, como para modales, tooltips, y popovers, que suelen necesitar estar en un nivel superior del DOM para evitar problemas de estilos y posicionamiento.
  
- useImperativeHandle: 

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$        


                                                                                                                   Nodejs

   
- fs en Nodejs: fs es la abreviación utilizada para FileSystem, el cual, como indica el nombre, es un sistema de manejador de archivos que nos proporcionará node para poder crear, leer, actualizar o eliminar un archivo, sin tener que hacerlo 
     nosotros desde cero. Así, crear un archivo con contenido será tan fácil como escribir un par de líneas de código, en lugar de tener que lidiar con los datos binarios y transformaciones complejas y de un nivel más bajo en la computadora.
     fs existe desde el momento en el que instalamos Nodejs en nuestro computador, por lo que, para utilizarlo, podemos llamarlo desde cualquier archivo que tengamos de nuestro código con la siguiente línea:
                                                                                   
                                                                                   const fs = require("fs");
                                                                                   
     De ahí en adelante todo el módulo de FileSystem estará contenido en la variable fs. Sólo debemos utilizarlo llamando sus métodos como una clase. Esto podremos hacerlo de 3 formas: síncrono, con callbacks o con promesas.                                                                                   
     Para utilzar de forma adecuada el fs, sólo utilizaremos la palabra Sync después de cada operación que queramos realizar. Las principales operaciones que podemos hacer con fs síncrono son:
       ✓ writeFileSync = Para escribir contenido en un archivo. Si el archivo no existe, lo crea. Si existe, lo sobreescribe.
       ✓ readFileSync = Para obtener el contenido de un archivo.
       ✓ appendFileSync = Para añadir contenido a un archivo. ¡No se sobreescribe!
       ✓ unlinkSync = Es el “delete” de los archivos. eliminará todo el archivo, no sólo el contenido.
       ✓ existsSync = Corrobora que un archivo exista!
       
- fs con callbacks: Funciona muy similar a las operaciones síncronas. Sólo que al final recibirán un último argumento, que como podemos intuir, debe ser un callback. Según lo vimos en las convenciones de callbacks de la clase pasada, el 
    primer argumento suele ser un error. Esto permite saber si la operación salió bien, o si salió mal. Sólo readFile maneja un segundo argumento, con el resultado de la lectura del archivo.
    Por último: el manejo por callbacks es totalmente asíncrono, así que cuidado dónde lo usas. Las principales operaciones que podemos hacer con fs con callbacks son:
      ✓ writeFile = Para escribir contenido en un archivo. Si el archivo no existe, lo crea. Si existe, lo sobreescribe. Al sólo escribir, su callback sólo maneja: (error)=>
      ✓ readFile = Para obtener el contenido de un archivo. Como pide información, su callback es de la forma: (error, resultado)=>
      ✓ appendFile = Para añadir contenido a un archivo. ¡No se sobreescribe!, al sólo ser escritura, su callback sólo maneja: (error)=>
      ✓ unlink = Es el “delete” de los archivos. eliminará todo el archivo, no sólo el contenido. Al no retornar contenido, su callback sólo es (error)=>
      
     Si queremos utilizar promesas, entonces qudarian como:
      ✓ fs.promises.writeFile
      ✓ fs.promises.readFile
      ✓ fs.promises.appendFile
      ✓ fs.promises.unlink    

- Crypto: 
- Process: 
- Child process
- Listeners: 
- Path: 
- Cluster: 
- OS: 


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$        

                                                                                                                   Express

- Express js es un framework minimalista que permitirá desarrollar servidores más complejos. Éste nos facilitará:
   ✓ Utilizar diferentes rutas para las peticiones.
   ✓ Mejorar la estructura de nuestro proyecto.
   ✓ Manejar funcionalidades más complejas y utilización de middlewares. 
  
  + Paso 1: npm init -y                                                                                                                   
    Express no es nativo de nodejs, por lo tanto, necesitaremos primero contar con un package.json para gestionar las dependencias a instalar. 
    Una vez que tenemos package.json en nuestra carpeta, podemos continuar instalando dependencias.
  
  + Paso 2: npm install express 
    Procedemos a instalar de manera local express js. Al ejecutar este comando, notaremos cómo se genera una carpeta node_modules, que es donde se encuentra almacenado express.
    A partir de este punto, ya contamos con la estructura elemental instalada, el resto es más “flexible”.

  + Paso 3: Estructurar el proyecto 
    Se recomienda tener una carpeta src, donde vivirá todo nuestro código, dentro del cual crearemos un archivo con el nombre “app.js”
    Finalmente, el archivo app.js ya puede importar la dependencia instalada de express js, ya sea por commonjs:   const express = require ("express");
    o bien por module (recordar colocar el type:”module” en package.json):   import express from "express";                                           
  
  + Ejemplo de una consulta en Express
     ✓ Estructurar un servidor basado en express, el cual escuche peticiones en el puerto 8080
     ✓ Realizar una función para el método GET en la ruta ‘/saludo’, el cual responderá con “¡Hola a todos, pero ahora desde express!”
     ✓ Ejecutar con nodemon (npm install -g nodemon) y probar en el navegador el endpoint generado.
     
- Método GET: Método del protocolo HTTP que permite indicar al servidor que deseamos hacer na consulta de obtención de datos.       .get() 
- Metodo POST: Sirve para “crear” recursos, POST se utiliza para operaciones donde no necesitamos  obtener un recurso, sino añadir uno. Algunos de los casos donde se utilizan son:
    ✓ Registrar un usuario
    ✓ Loguear un usuario
    ✓ Crear un producto
    ✓ Crear una mascota
    ✓ Crear un carrito de compra
    ✓ Enviar información para un correo electrónico.
  Se apoya del recurso req.body, donde elbody representa la información que el cliente envía para crear.
- Método PUT: Sirve Para poder trabajar con PUT, no sólo enviamos el body en el request, sino que demás mandamos por params el id, nombre,  cualquier identificador para que el servidor epa qué recurso específicamente debe ctualizar.
  Hay dos formas de actualizar un recurso: actualizar sólo los campos requeridos, o bien mandar a actualizar el objeto completo, ambas formas son válidas cuando hablamos de actualización, y dependerá del contexto.
- Método DELETE: Como bien lo indica el nombre, este método lo utilizamos cuando queremos eliminar algún recurso. Aquí no es necesario enviar nada desde el body, sin embargo, sí es importante indicar en el req.params el identificador para 
  que el servidor reconozca qué recurso debe eliminar.
  
  
- Metodos en express js
  > // app.set(name, value); is used to assign the setting name to value. You may store any value that you want, but certain names can be used to configure the behavior of the server. 

      
- Objeto request: Objeto usado dentro de los servicios de express para poder realizar consultas más complejas.
  The req object represents the HTTP request and has properties for the request query string, parameters, body, HTTP headers, and so on. In this documentation and by convention, the object is always referred to as req (and 
  the HTTP response is res) but its actual name is determined by the parameters to the callback function in which you’re working.  
  
  > req.query: Como su nombre lo indica, query refiere a las múltiples consultas que se pueden hacer a un determinado endpoint, basta conque en la url coloquemos el símbolo ? , entonces express reconocerá que hay que meter información al 
    objeto req.query para poder utilizarlo en el endpoint. Cuando buscamos algo en nuestro navegador, llamamos a un endpoint haciendo un determinado query. Se expresa como:    ?key=valor
    
    Conforme incrementa el dinamismo en las urls, es importante configurar el servidor para que reciba datos complejos desde la url, por ello hay que utilizar la línea:
                   app.use(express.urlencoded({ extended: true }));
    La línea anterior permitirá que el servidor pueda interpretar mejor los datos complejos que viajen desde la url, y mapearlos correctamente en el req.query.
    Es decir, cuando hagamos una peticion POST, cuando lleguen, que podamos recivir esos datos. Sino, llegara un objeto vacio. 
    
    Tambien tenemos la siguiente linea que dice que, cuando nosotros hagamos peticiones por POST, lleguen. O de lo cotrario, nos llegarian como undefined.
                   app.use(express.json());
  
  > req.params: Se utiliza cuando necesitamos obtener elementos dinámicos desde la ruta que está llamando el cliente. para poder definir un “parámetro” dentro de la ruta a trabajar, basta con colocar el símbolo de dos puntos (:) antes del 
    parámetro, de esta manera, express reconoce que queremos que ese elemento sea dinámico.
    
  > ¿Qué diferencia hay con params? 
    La principal diferencia que hay entre req.params y req.query, es que en req.query puedo meter la cantidad de consultas que yo así desee, ya que las queries no vienen inmersas en la ruta, sino que son un elemento aparte.
    Así, si desconozco el número de cosas que se van a consultar en mi ruta, la mejor opción es utilizar queries, mientras que, si sólo necesito un número específico y reducido de parámetros, habría que optar por params
    Al final, no hay una mejor que otra, sirven para casos diferentes e incluso podemos utilizar ambas en la misma consulta. 
    
  > req.body:  
  
  > next(): Esta funcion representa un parametro en adicional a req y res (req, res, next) y se usa en middlewares, generalmente cuando se manejan errores. Si el middleware no presentan ningun inconveniente, la funcion next() no tendra 
    ningun parametro, es decir, no hay error que enviar. Pero en caso de haberlo, entonces se debera mandar ese error dentro de los parentesis.
        
- Router en Express: Un router en express nos permitirá separar los endpoints “comunes” en entidades separadas que fungirán como “mini aplicaciones”, las cuales tomarán peticiones que concuerden con dicho endpoint y así redireccionarse a 
  esta mini aplicación. De esta manera, nuestro código resultará más organizado, y las diferentes entidades tendrán aislado el comportamiento interno, como configuraciones, middlewares, etc.
  
  > ¿Cómo aplicar un router? Primero recordemos la estructura de nuestro proyecto, hasta el momento, sabemos que la estructura básica de nuestro proyecto consiste en la distribución como lo indica la imagen: una carpeta donde vive el 
    proyecto, dentro una carpeta src donde vivirá nuestro código, y nuestro servidor dentro.
    Despues, agregaremos una carpeta “routes” donde vivirán nuestros diferentes routers (Nota que app.js se queda fuera de routes, pero sigue dentro de src).

- Servicio de archivos estáticos con Express: 
   ✓ Nuestro servidor tiene la posibilidad de alojar recursos que pueden ser visibles para el cliente de manera directa.
   ✓ Podemos configurar una carpeta para que el usuario pueda acceder y ver dichos recursos de manera directa sólo con acceder a la ruta donde se encuentra ubicada.
   ✓ En este curso y en proyectos profesionales podrás encontrar estos archivos en la carpeta “public”, haciendo referencia como dice el nombre, a recursos públicos de fácil acceso para el cliente.
  
  Los dos casos principales para los cuales encontrarás el uso de esta carpeta “public” para archivos estáticos son:
   ✓ Cuando necesitemos alojar imágenes y servirlas directamente al cliente.
   ✓ Cuando necesitemos alojar una página web en todos sus sentidos: html, css, js. En esta clase haremos una página sencilla para mostrar el alcance de public.

- ¿Cómo convertir una carpeta en un recurso estático? 
  Para poder utilizar los recursos de una carpeta de manera estática, basta conque en el servidor especifiquemos como “express.static” dicha carpeta con la siguiente sintaxis: 
                                                               app.use(express.static('public'));
  Indicamos que, todo lo que viva en la carpeta public, podrá ser accedido directamente desde la carpeta public. A continuación podemos cargar los archivos que queramos en el directorio public:
  http://localhost:3000/hello.html
  http://localhost:3000/images/kitten.jpg
  Nota: Express busca los archivos relativos al directorio estático, por lo que el nombre del directorio estático no forma parte del URL.
  
  > Prefijo virtual: Para crear un prefijo virtual (donde el path de acceso no existe realmente en el sistema de archivos) para los archivos servidos por express.static, debemos especificar un path de acceso de montaje para el directorio 
    estático:  app.use('/static', express.static('public'));
    Así podemos cargar los archivos que hay en el directorio public desde el prefijo /static.
    http://localhost:3000/static/hello.html
    http://localhost:3000/static/images/kitten.jpg
    
  > Path absoluto: El path que se proporciona a la función express.static es relativo al directorio desde donde inicia el proceso node. Por eso si ejecutamos la aplicación Express desde cualquier otro directorio, es más seguro utilizar el 
    path absoluto del directorio al que desea dar servicio:   app.use('/static', express.static(__dirname + '/public'))
    
- middleware: Operación intermedia que ocurre entre la petición a la base de datos y la entrega del documento o los documentos correspondientes. 
  Funciones que se colocan en medio de la ruta y el callback (req, res) que se ejecutarán antes de comenzar a procesar la petición.
  Cada vez que utilizamos un app.use estamos utilizando un middleware. Éstas son operaciones que se ejecutan de manera intermedia entre la petición del cliente, y el servicio de nuestro servidor.
  Como lo indica el nombre: “middleware” hace referencia a un intermediario, siempre se ejecuta antes de llegar al endpoint que corresponde. los middlewares se ejecutan EN ORDEN, eso quiere decir que, si algún middleware depende de que se 
  haya realizado otra operación ejecutada por un middleware previo, los coloquemos en cascada según prioridad. Podemos utilizar un middleware para:
    ✓ Dar información sobre las consultas que se están haciendo (logs) 
    ✓ Autorizar o rechazar usuarios antes de que lleguen al endpoint (seguridad) 
    ✓ Agregar o alterar información al método req antes de que llegue al endpoint (formato) 
    ✓ Redireccionar según sea necesario (router) 
    ✓ En ciertos casos, finalizar la petición sin que llegue al endpoint (seguridad)
    
- Tipos de middleware: Una aplicación Express puede utilizar los siguientes tipos de middleware:
  ✓ Middleware a nivel de aplicación
  ✓ Middleware a nivel endpoint
  ✓ Middleware a nivel del Router
  ✓ Middleware de manejo de errores
  ✓ Middleware incorporado
  ✓ Middleware de terceros
  
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$        
                                                       
                                                                                                                   Multer  

- Middleware de carga de archivos: MULTER Middleware desarrollado para poder realizar carga de archivos dentro de las peticiones, con el fin de que el cliente pueda manejar archivos como imágenes, vídeos o documentos; dentro de una petición.
  En ocasiones el cliente necesitará subir una imagen, un vídeo o un archivo, según sea nuestra aplicación, ello nos lleva a configurar nuestro servidor para soportar estos archivos y poder almacenarlos en donde nosotros le indiquemos. Al
  ser de terceros, necesitaremos instalarlo para poder utilizarlo. 
    1) MULTER es una dependencia de terceros, de manera que, al igual que express, necesitaremos instalarlo dentro de nuestro package.json
    2) Una vez que tenemos MULTER instalado, podemos importarlo en nuestro proyecto y configurarlo donde lo necesitemos (puede ser directamente en app, o bien se recomienda hacerlo en un archivo al mismo nivel de app llamado “utils”) Contar 
       con un uploader externo a app.js, brindará más dinamismo al momento de utilizarlo, ya que podemos colocarlo en el router que necesitemos y no necesariamente instanciarlo a nivel general
    3) Una vez que nuestro uploader está listo para utilizarse, podemos importarlo en el router que necesitemos y colocarlo en la ruta donde lo necesitemos, recuerda que, al ser un middleware, éste va enmedio de la ruta y de la función 
       callback (req,res).    app.post("/", uploader.single("file"), function(request, response){}
     
       Podemos utilizar el uploader de dos formas principalmente:
         ✓ uploader.single(‘nombre del campo’): permitirá subir un único archivo, su resultado estará en req.file
         ✓ uploader.array(‘nombre de campos’): permitirá subir múltiples archivos, su resultado estará en req.files
   
   Cuando subimos un archivo (imagen, vídeo, etc), estamos hablando de un flujo de datos. lo cual no puede plasmarse en un JSON. Cuando enviamos información a un endpoint donde sabemos que utilizamos MULTER, debemos enviarlo como FormData, 
   no como JSON.
   
                                                                                                               
                                                                                                                   
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$        

                                                                                                                   Websocket
                                                                                                                   
- Websocket: es un protocolo de comunicación basado en TCP para poder establecer esa conexión entre el cliente y el servidor, justo como sabemos, es el mismo objetivo que cubre HTTP.  
  A pesar de que websocket y HTTP son protocolos como lo mencionamos anteriormente, websocket tiene una característica muy importante: Su protocolo TCP establece dos endpoints de comunicación, a cada endpoint se le conoce como socket.
  El contar con estos dos sockets permitirá establecer una comunicación bidireccional entre el cliente y el servidor. La comunicación bidireccional implica: 
   ✓ Que el cliente puede obtener recursos del servidor cuando lo solicite (como en HTTP).
   ✓ Que el servidor pueda entregar información al cliente sin necesidad de que el cliente haga una petición.                      
   
  Websockets es un protocolo excelente para esta situación ya que:  
   ✓ El cliente no tendrá que estar actualizando la página constantemente 
   ✓ En cuanto el servidor reciba una actualización de una nueva puja, actualizará a todos los clientes conectados, permitiendo dar información en tiempo real
   ✓ Una vez que termina la subasta, el socket se cierra y el servidor deja de notificar innecesariamente al cliente.

- Hanshake: Acuerdo entre cliente y servidor que permite establecer una conexión abierta entre ambos puntos.      
   
- Funcionamiento de un Websocket: Primero, el cliente tiene que enviar una solicitud HTTP llamada Handshake (apretón de manos). Este apretón de manos será un “acuerdo” o “contrato” de confianza para que el servidor pueda actualizar al 
  cliente sin que éste se lo pida. El servidor recibe la petición de Handshake y procede a “responderle el saludo”, a esto se le llama “Abrir conexión”.
  A partir de este punto, el canal queda abierto de manera bidireccional, por lo que el cliente se puede comunicar con el servidor cuando quiera y viceversa. La comunicación es “persistente” hasta que alguno de los dos lados decida cerrar el 
  canal de comunicación.
   
- El protocolo Websocket: principios   
  ✓ Websocket permitió por primera vez acceder a una web de forma dinámica en tiempo real.
  ✓ Basta con que el cliente establezca una conexión con el servidor, que se confirma ediante el llamado apretón de manos o Websocket Protocol Handshake.
  ✓ Con él, el cliente envía al servidor todos los datos de identificación necesarios para el intercambio de información.
  ✓ El canal de comunicación queda “abierto” tras el handshake.
  ✓ El servidor puede activarse por sí mismo y poner toda la información a disposición del cliente, sin que este tenga que pedírselo. Si dispone de nueva información, se lo comunica al cliente, sin necesidad de recibir una solicitud 
    específica para ello.
  ✓ Las notificaciones push de las páginas web funcionan según este principio.
  
- Websocket y comparación con HTTP: HTTP no es reemplazo de Websocket, ni websocket es reemplazo de HTTP. Ambos son complementos que se pueden utilizar en conjunto, con el fin de hacer sistemas completos y complejos.
  HTTP --> Son peticiones al servidor que esperan una respuesta. Como un walkie talkie. 
  Websocket --> Es un canal abierto entre servidor y cliente. Como una llamada telefónica.
  HTTP --> Se solicita información y se espera una respuesta. Ej: un formulario de login
  Websocket --> Se usa para comunicación en tiempo real. Ej: un chat
  HTTP --> Se usa para consumir APIs y recursos web Se usa para escuchar información en tiempo real
  Protocolo HTTP Es un protocolo de comunicación
  HTTP --> Conexión de una sola vía 
  Websocket --> Conexión de doble vía
  HTTP --> No sustituye a WebSockets 
  Websocket --> No sustituye a HTTP

- Socket.io: 
  ✓ Es una biblioteca de Javascript para poder implementar los sockets anteriormente mencionados.
  ✓ Debido al funcionamiento que hemos visto en clase. socket.io debe instanciarse tanto de lado del cliente, como del servidor.
  ✓ Permite utilizar todo el potencial mencionado de los websockets, y cuenta con una API casi idéntica para cliente y para servidor. 
  ✓ Socket.IO utiliza principalmente el protocolo Websocket proporcionando la misma interfaz.
  ✓ Se puede usar como un contenedor para Websocket aunque proporciona muchas más funciones, incluida la transmisión a múltiples sockets, el almacenamiento de datos asociados con cada cliente y E/S asíncronas.
  ✓ Se puede instalar con npm.
  ✓ Fiabilidad: Las conexiones se establecen incluso en presencia de:
  ✓ proxies y balanceadores de carga.
  ✓ firewall personal y software antivirus.
  ✓ Soporte de reconexión automática: A menos que se le indique lo contrario, un cliente desconectado intentará siempre volver a conectarse, hasta que el servidor vuelva a estar disponible.
  ✓ Detección de desconexión: Se implementa un mecanismo de heartbeat, lo que permite que tanto el servidor como el cliente sepan cuando el otro ya no responde.
  ✓ Soporte binario: Se puede emitir cualquier estructura de datos serializable, que incluye:
  ✓ ArrayBuffer y Blob en el navegador
  ✓ ArrayBuffer y Buffer en Node.js


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$        

                                                                                                                   MONGODB
                                                                                                                   
- Usar mongodb en la terminal: 
  1) correr .\mongod.exe  en powershell
  2) Abrir otra ventana de powershell y copiar el siguiente link --> cd 'C:\Program Files\MongoDB\Server\7.0\bin'
  3) Despues ejecutar --> .\mongos.exe                                                                                                            

- Base de datos: Una base de datos no es más que una recopilación organizada de datos. Dichos datos deben compartir algún contexto y son almacenados con poder convertirse posteriormente en información útil para utilizarse dentro de algún
  sistema. La base de datos sólo se encargará de almacenar dichos datos.
  Algunas de las cosas que podemos señalar sobre la utilidad de una base de datos son:
   ✓ Almacenamiento más seguro: Los datos que viven en una base de datos no son modificables directamente, por lo que éstos no pueden ser cambiados tan fácilmente.
   ✓ Segmentación de datos: Podemos separar los datos en “contextos”, permitiendo así tener separados los datos de interés. 
     ○ Separar clientes potenciales de clientes sólo interesados. 
     ○ Separar productos existentes de productos fuera de stock 
     ○ Separar diferentes usuarios por género, nacionalidad, plan, etc.
   ✓ Gestión sencilla una vez configurada: Una vez que hemos definido los esquemas principales de nuestra base de datos, podremos realizar operaciones sobre estos datos como:
   ✓ Filtrar
   ✓ Ordenar
   ✓ Buscar datos específicos.
   ✓ Actualizar un conjunto de datos sin afectar o tocar otros datos.

- Modelo relacional: Gestión de datos que consiste en representar éstos como tablas relacionadas con el fin de brindar una estructura de relación sólida entre ellos.
- Modelo no relacional: Gestión de datos flexible que sustituye las tablas relacionadas, por colecciones, garantizando facilidad y dinamismo en el manejo de los datos.
- Base de datos relacional: se refiere a estructura, elación, dependencia y de cambio controlado.
- Base de datos no relacional:  refiere a algo enos estructurado, con relaciones y ependencias más flexibles, y de cambios umamente rápidos.

- Inconsistencia de datos

- CRUD: es un acrónimo que hace referencia a las cuatro operaciones fundamentales de una base de datos:
  ✓ C : Create (Crear un dato, insertarlo en la base de datos)
  ✓ R : Read (Leer un dato, mostrarlo al cliente)
  ✓ U : Update (Actualizar un dato, cambiar su información interna)
  ✓ D : Delete (Eliminar un dato, removerlo de nuestra colección.
  
  
- Comandos de apoyo
  ✓ show dbs : Muestra las bases de datos existentes.
  ✓ use <db name>: Crea una nueva base de datos (en caso de no existir) y se posiciona sobre ella
  ✓ db: Muestra en qué base de datos estamos posicionado.
  ✓ show collections: Muestra todas las colecciones disponibles en la base de datos posicionada.
  ✓ db.createCollection(name): Crea una colección en la base de datos posicionada.
  ✓ db.dropDatabase(): Elimina la base de datos actual.
  ✓ db.collection.drop(): Elimina la colección de la base de datos posicionada.

- Primeros comandos CRUD: CR
  ✓ db.collection.insertOne(doc) : Agrega un nuevo documento a la colección seleccionada.
  ✓ db.collection.insertMany(docs): Agrega múltiples documentos a la colección seleccionada (dado un arreglo de documentos).
  ✓ db.collection.findOne(opt): Busca un elemento que cumpla con los criterios de búsqueda (opt), devuelve el primer documento que cumpla con dicho criterio.
  ✓ db.collection.find(opt):Devuelve todos los documentos que cumplan con dicho criterio.
  ✓ db.collection.find(opt).pretty(): Añadido para hacer más presentables los resultados de un find()    

- Conteo de datos: Los comandos de conteo para determinar el número de documentos en una colección son
  ✓ db.collection.estimatedDocumentC count() Cuenta el estimado más próximo al número de documentos según su metadata.
  ✓ db.collection.countDocuments(opt) Cuenta los documentos que cumplan con el criterio definido en las opciones (opt).
  
- opt (options): agregando opciones
  En muchas consultas encontramos el elemento (opt), esto hace referencia a las opciones de filtros de búsqueda que podemos realizar al momento de buscar un valor, la sintaxis elemental de un opt es: {propiedad:valor}
                                                                             db.users.find({gender: "M})
        
- Filtros: Las búsquedas del mundo real no siempre requieren que un valor sea igual a otro. En ocasiones necesitamos que sea menor, mayor, diferente de, entre otras cosas. Los filtros pueden agregarse dentro de los elementos de criterio 
  (opt) con ayuda del símbolo $, además, podemos agregar más de un filtro para asegurarnos que el documento se ajuste a criterios muy específicos. Entonces, la sintaxis general será:
                                                                             db.coll.find( {key: {$operator: val}} )
                                                                             
- MongoDB: Operadores para Filtros de Query
  ✓ $and: Realiza operación AND -> sintaxis: {$and: [ {},{} ] }
  ✓ $or: Realiza operación OR -> sintaxis: {$or: [ {},{} ] }
  ✓ $lt: Coincide con valores que son menores que un valor especificado.
  ✓ $lte: Coincide con valores menores o iguales a un valor especificado.
  ✓ $gt: Coincide con valores mayores a un valor especificado.
  ✓ $gte: Coincide con valores mayores o iguales a un valor especificado.
  ✓ $ne: Coincide con valores que no son iguales a un valor especificado.
  ✓ $eq: Selecciona los documentos que son iguales a un valor especificado.                                                                                        
  ✓ $exists: Selecciona los documentos según la existencia de un campo.
  ✓ $in: Selecciona los documentos especificados en un array. sintaxis: {key:{$in: [array of values] } }
  ✓ $nin: Coincide con ninguno de los valores especificados en un array.
  ✓ $size: Coincide con el número de elementos especificados.
  ✓ $all: Coincide con todos los valores definidos dentro de un array.
  ✓ $elemMatch: Coincide con algún valor definido dentro del query.                                                                                             
  
- MongoDB: Búsqueda Avanzada
  ✓ db.coll.distinct( val ) devuelve un array con los distintos valores que toma un determinado campo en los documentos de la colección.
  ✓ db.coll.find({doc.subdoc:value}) Se utiliza para filtrar subdocumentos.
  ✓ db.coll.find({name: /^Max$/i}) filtra utilizando expresiones regulares
  
- Proyecciones: En ocasiones no necesitamos toda la información de un documento. Si tenemos un documento con 100 propiedades, podemos definir sólo las propiedades que queremos obtener.
  Una proyección se incluye al momento de hacer una búsqueda, (siempre como segundo argumento) y es el equivalente a decirle a la base de datos: “sólo necesito ésto”
  Así, podríamos decir db.users.find({},{name:1}); Lo cual indica que, el campo “name” es el único que necesitamos obtener por parte del documento, ahorrándonos espacio y complejidad en el resultado
  
- Sort: Sirve para poder hacer un ordenamiento de la información. El ordenamiento se define con 1 o -1 para hacer el ordenamiento ascendente o descendente respectivamente.
  La sintaxis es: db.collection.find().sort({val_A:1,val_B:-1})
  La razón por la cual podemos agregar múltiples valores de ordenamiento, es en caso de que dos documentos tengan el mismo valor, podamos ordenarlos bajo otro criterio  
  
- Skip: Omite el número de documentos indicados:Podemos usarlo cuando hagamos paginaciones, cuando necesitemos ignorar un valor que sabemos que es innecesario, etc. Su sintaxis es: .skip(offset)
- Limit: Limita el número de documentos devueltos. De manera que podamos hacer diferentes niveles de paginación (Tu página puede devolver 5 elementos por página, o bien 100, tú decides). Su sintaxis es: .limit(num)  
  
- CRUD (update): Las operaciones Update se pueden realizar de dos maneras: Actualizar un documento, o actualizar múltiples documentos.
  ✓ db.collection.updateOne(query,update,option)
  ✓ query: sirve para filtrar qué elementos actualizar (usa los filtros iguales al find)
  ✓ update: Apartado para indicar qué actualizar de los documentos que cumplen con el filtro. Update tiene sus propios operadores como $set, $unset, $inc, $rename, $mul, $min, $max
  ✓ option: Opciones a tomar en cuenta para la actualización (como upsert, que inserta el valor en caso de que el documento a actualizar ni siquiera exista).
  ✓ db.collection.updateMany(query,update,options) Actualiza múltiples documentos que cumplan con el criterio.
  
- CRUD (Delete): Nuestra última operación es para eliminar datos, si bien hay muchas variantes de una eliminación, sólo veremos las dos principales.
✓ db.collection.deleteOne({key:val}) : Elimina sólo el primer elemento que cumpla con el criterio, se usa principalmente para encontrar identificadores específicos. Se recomienda no utilizar si somos conscientes de que el valor a buscar no 
   es repetido.
✓ db.collection.deleteMany({key:val}) : Elimina todos los documentos que cumplan con el criterio, se usa cuando sabemos que más de un valor va a contar con ese valor y necesitamos hacer una limpieza general.  


- Mongoose (population): Operación que permite transformar la referencia de un documento en su documento correspondiente en la colección indicada.
  Una population implica obtener un documento referenciado dentro de otro documento, con el fin de obtener ambos en una sola búsqueda. Consiste en almacenar el id de un documento, como propiedad de otro documento. A esto se le     
  conoce como “referencia”. Populate hace referencia a “poblar” de un id a un documento completo. (referencia a la población humana).
  Algunas cosas a considerar antes de comenzar con su uso:
    ✓ populate es un método propio de mongoose, por lo que tenemos que instalarlo.
    ✓ Hay que tener siempre claro el nombre de la propiedad dentro del objeto, así también como la referencia de la colección, para poder hacer un populate efectivo.
    ✓ Recuerda no guardar directamente el valor a referenciar en el _id, sino asignarle otro nombre (se profundizará en el ejemplo).

- Mongoose (indexing): Indexes support the efficient execution of queries in MongoDB. Without indexes, MongoDB must perform a collection scan, i.e. scan every document in a collection, to select those documents that match the query 
  statement. If an appropriate index exists for a query, MongoDB can use the index to limit the number of documents it must inspect.
  Es un recurso utilizado en MongoDB para poder hacer consultas mucho más rápidas al colocarse en una propiedad de un documento. Éste nos permitirá tener una referencia previa al momento de buscar un documento, con el fin de evitar recorrer 
  toda la colección, documento por documento, hasta encontrar dicho valor. El índice se asocia a un atributo del documento y permite que las búsquedas se hagan desde puntos específicos, evitando el recorrido completo de la colección.
  Prever un buen plan de indexación evitará problemas de lentitud en las consultas y se considera una práctica necesaria a nivel enterprise, al momento de configurar los schemas de nuestros distintos modelos
  
  Un índice no debe ser utilizado en todos los campos, sólo deben ser utilizados en los campos que sepamos tienen repercusión en nuestras búsquedas. Colocar un índice en cada campo de cada documento, significa alentar procesos de escritura 
  en cada insert, así también como generar un almacenamiento adicional e innecesario en la base de datos.
  
  > Tipos de indices: Prever un buen plan de indexación evitará problemas de lentitud en las consultas y se considera una práctica necesaria a nivel enterprise, al momento de configurar los schemas de nuestros distintos modelos.
     ✓ compound: Se utiliza cuando requerimos utilizar más de una indexación y queremos definir el orden con el cual se realiza el ordenamiento (ordenando con 1 para ascendente y -1 para descendente, igual que un sort: {campo: 1 , campo: -1}
     ✓ multikey: Se utiliza cuando requerimos hacer una indexación de valores que se encuentran de manera interna en un array.
     ✓ text: Se utiliza para poder basarse en búsquedas de palabras “específicas” con el fin de poder tomar referencia de un texto a partir de dichas palabras.
     ✓ geospatial: Se utiliza para almacenar data geoespacial de dos coordenadas, utiliza una esfera 2d para poder trabajar los datos. 

  > population: Operación que permite transformar la referencia de un documento en su documento correspondiente en la colección indicada.
    Una population implica obtener un documento referenciado dentro de otro documento, con el fin de obtener ambos en una sola búsqueda. Consiste en almacenar el id de un documento, como propiedad de otro documento. A esto se le     
    conoce como “referencia”. Populate hace referencia a “poblar” de un id a un documento completo. (referencia a la población humana).
    Algunas cosas a considerar antes de comenzar con su uso:
      ✓ populate es un método propio de mongoose, por lo que tenemos que instalarlo.
      ✓ Hay que tener siempre claro el nombre de la propiedad dentro del objeto, así también como la referencia de la colección, para poder hacer un populate efectivo.
      ✓ Recuerda no guardar directamente el valor a referenciar en el _id, sino asignarle otro nombre (se profundizará en el ejemplo)

  > Configurando una population por default: Para poder “poblar” el resultado de la operación find() del estudiante y obtener los cursos, fue necesario llamar a “populate” después de la operación. Sin embargo, tener que colocar el populate 
    puede resultar molesto si utilizamos constantemente el modelo de estudiante. Mongoose tiene la posibilidad de definir “middlewares” para sus documentos y modelos con el fin de automatizar operaciones que consideremos recurrentes. 

- Mongoose (aggregation): Consiste en la realización de múltiples operaciones, eneralmente sobre múltiples documentos. ueden utilizarse para:              https://stackoverflow.com/questions/24714166/full-text-search-with-weight-in-mongoose
    ✓ Agrupar documentos con base en un criterio específico.
    ✓ Realizar alguna operación sobre dichos documentos, con el fin de obtener un solo resultado.
    ✓ Analizar cambios de información con el paso del tiempo.

  > Funcionamiento: Los aggregation pipelines consistirán en un conjunto de pasos (stages), donde cada paso corresponderá a una operación a realizar. Podemos definir tantas stages como necesitemos con el fin de llegar a los resultados 
    esperados. Los documentos resultantes de la stage que finalice, se utilizan como “input” de la siguiente stage, y así sucesivamente hasta llegar al final. 
    Un ejemplo de un pipeline de aggregation puede ser: 
    1. Primero filtra los documentos que tengan un valor x mayor a 20 2. Luego ordénalos de mayor a menor 3. Luego en un nuevo campo devuelve el valor máximo 4. Luego en un nuevo campo devuelve el valor mínimo 5. Luego en un nuevo campo 
       devuelve la suma total de todos los documentos

  > Principales stages disponibles en un aggregation pipeline
    ✓ $count : Cuenta el número de documentos disponibles que se encuentren en la stage actual.
    ✓ $group: Permite agrupar los documentos disponibles en nuevos grupos según un criterio especificado. cada grupo cuenta con un _id nuevo, además de los valores acumulados \
    ✓ $limit: Limita el número de documentos que saldrán de dicha stage.
    ✓ $lookup: Permite realizar un “left join” (combinación de campos), de una colección de la misma base de datos a los documentos de la stage actual.
    ✓ $set / $addFields : Agregan una nueva propiedad a los documentos que se encuentren en dicha stage.
    ✓ $skip: Devuelve sólo los documentos que se encuentren después del offset indicado.
    ✓ $sort: Ordena los documentos en la stage actual.
    ✓ $match -->  Devuelve sólo los documentos que cumplan con un criterio de búsqueda, podemos colocar filtros comunes aquí. Filters the document stream to allow only matching documents to pass unmodified into the next pipeline stage. 
      It uses standard MongoDB queries. For each input document, outputs either one document (a match) or zero documents (no match).
    ✓ $group --> Groups input documents by a specified identifier expression and applies the accumulator expression(s), if specified, to each group. Consumes all input documents and outputs one document per each distinct group. The output 
       documents only contain the identifier field and, if specified, accumulated fields.
    ✓ $sum --> Returns a sum of numerical values. Ignores non-numeric values.
    ✓ $first --> Returns the result of an expression for the first document in a group of documents. Only meaningful when documents are in a defined order.
    ✓ $sort ---> Reorders the document stream by a specified sort key. Only the order changes; the documents remain unmodified. For each input document, outputs one document.
    ✓ $push --> returns an array of all values that result from applying an expression to documents.
    ✓ $$ROOT --> significa los resultados del stage anterior
    ✓ $project --> Reshapes each document in the stream, such as by adding new fields or removing existing fields. For each input document, outputs one document. Takes a document that can specify the inclusion of fields, the suppression of 
       the _id field, the addition of new fields, and the resetting of the values of existing fields. Alternatively, you may specify the exclusion of fields.
    ✓ $merge --> Escribe los resultados del pipeline en una colección. Debe ser la última stage del pipeline para poder funcionar.
       Writes the resulting documents of the aggregation pipeline to a collection. The stage can incorporate (insert new documents, merge documents, replace documents, keep existing documents, fail the operation, process documents with a 
       custom update pipeline) the results into an output collection. IT MUST BE USED BY USING A $project BEFORE.    
    
    
- Mongoose (Paginate): Pagination is the process of separating print or digital content into discrete pages. For print documents and some online content, pagination also refers to the automated process of adding consecutive numbers to 
  identify the sequential order of pages.                                  https://stackoverflow.com/questions/5539955/how-to-paginate-with-mongoose-in-node-js
  
  > mongoose-paginate-v2 is a pagination library having a page wrapper. The main usage of the plugin is you can alter the return value keys directly in the query itself so that you don't need any extra code for transformation.                                    

  > Model.paginate([filter], [options], [callback])
    ✓ docs: Los documentos devueltos en la página
    ✓ totalDocs: Los documentos totales de la consulta realizada.
    ✓ limit: Límite de resultados por página.
    ✓ page: Página actual en la que nos encontramos
    ✓ totalPages: Páginas totales que pueden ser solicitadas en la búsqueda.
    ✓ hasNextPage: Indica si es posible avanzar a una página siguiente.
    ✓ nextPage: Página siguiente en la búsqueda
    ✓ hasPrevPage: Indica si es posible retroceder a una página anterior.
    ✓ prevPage: Página anterior en la búsqueda.
    ✓ pagingCounter: Número de documento en relación con la página actual      
    
- Mongoose (properties)
   > index: This will help the database engine to scan through the needed documents and not all of them.
   > virtual: Virtuals are document properties that you can get and set but that do not get persisted to MongoDB. The getters are useful for formatting or combining fields, while setters are useful for de-composing a single value into 
     multiple values for storage.

- Mongoose (middlewares)
   > document: Document middleware is specific to individual documents (instances of a model). It’s triggered during actions like save, validate, remove, updateOne, and deleteOne.
   > model: Model middleware operates on entire collections of documents. It’s triggered during actions like insertMany.
   > query: Aggregate middleware is for operations performed using MyModel.aggregate(). It allows you to modify aggregation pipelines.
   > aggregation: Query middleware lets you modify queries before or after they are executed. It’s triggered during actions like find, findOne, update, and remove.

- Mongoose (functions): Database logic should be encapsulated within the data model. Mongoose provides 2 ways of doing this, methods and statics. Methods adds an instance method to documents whereas Statics adds static "class" methods to the 
  Models itself.
   > methods: It's a method that it's gonna be available on all documents of a certain collection
   > statics: statics are the methods defined on the Model. Those functions are only used ONLY in the model and that exist ONLY in the model.


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$        

                                                                                                                   Cookies, auth, JWT
    
    
- Cookies: Cuando desarrollamos un sitio web, tenemos que contemplar que la forma de interactuar de un cliente suele ser diferente, entonces es importante tener algún recurso para saber información sobre ciertos detalles de información y 
  comportamiento de un cliente, para que el servidor pueda usar eso a su favor. Para seguir un rastro de los clientes de nuestro sitio web y poder obtener un poco más de información de contacto y/o de comportamiento sobre los clientes que 
  nos visitan, se utilizan las cookies.
  Una cookie es un pequeñísimo archivo de texto donde podremos almacenar información dentro del navegador, de manera que pueda viajar entre las peticiones y sirva como un ligero contenedor de información necesaria para poder procesar ciertas 
  peticiones. Las cookies viven en el navegador, por lo que son fácilmente accesibles por múltiples elementos externos. Por ningún motivo guardamos información sensible en una cookie. Nunca guardamos información de métodos de pago, 
  contraseñas, ni cualquier dato que pudiera comprometer la seguridad del clie nte. Algunos de los datos que se suelen guardar en una cookie son:
    ✓ Nombres de usuario
    ✓ IDs de sesiones (que abarcaremos más adelante)
    ✓ Preferencias de navegación para tu página. 
  
  > Rastros que suele dejar un usuario al navegar en la web:
    ~ El cliente hace login --> La cookie almacena el id de la sesión
    ~ El cliente pone el fondo de la página en modo “obscuro” --> La cookie almacena: ✓ Id de sesión ✓ preferencias de configuración en página 
    ~ El cliente busca --> productos específicos --> La cookie almacena: ✓ Id de sesión ✓ preferencias de configuración en página ✓ Búsquedas recientes
    
  > Caracteristicas: 
     ✓ A las cookies se les puede configurar un tiempo de vida. Una vez finalizado el mismo, la cookie se elimina del navegador.
     ✓ Al almacenarse del lado del cliente, el espacio con el que se cuenta es limitado, por lo que se recomienda elegir de forma adecuada lo que se vaya a guardar como cookie.
     ✓ Podemos asignarles claves secretas para poder aumentar la seguridad
     ✓ Viven en el navegador, así que no guardamos datos sensibles
  
  > Firmar una cookie: Como las cookies son almacenadas en el navegador, pueden llegar a ser alteradas mucho más fácilmente que si ésta viviera en el servidor. Se necesita agregar un factor de seguridad para que la cookie se “invalide” en 
    caso de que haya sido modificada. No podemos evitar que alguien externo altere la cookie, pero sí podemos indicar que, en caso de que la cookie ya no sea exactamente idéntica a la generada, entonces la pase como cookie inválida.

  > Session: Una sesión es un vínculo que se genera cuando el cliente conecta con un servidor, este vínculo se representa por una sessionId, la cual se guarda en el navegador como identificador de la sesión. 
  > Storage: Lugar donde se almacenan las sesiones del lado del servidor. Es donde se consultan y comparan las sessionId.
  > MemoryStorage : Almacenamiento por defecto de sesiones por express-session. Si el servidor cae, las sesiones caen.
  > FileStorage: Almacenamiento alternativo que permite guardar las sesiones en archivos en una carpeta indicada. Cuando el servidor cae, aún puede consultar las sesiones de los archivos después.
  > MongoStorage: Almacenamiento alternativo de sesión que permite guardar las sesiones en una base de datos. Es más accesible ya que tiene un sistema de autogestión que permite limpiar las sesiones expiradas.    
    
- Autorizacion: Es el proceso por el cual el servidor decide si, a pesar de las credenciales que tienes, tienes permitido acceder a un recurso o no. Es decir, que autorizar no hace referencia a que el servidor no sepa quién eres.  

- Autenticación: Para que un cliente pueda autenticarse, debe existir un registro previo almacenado en algún lado. El cliente envía un identificador (como un email) y el servidor lo buscará en su base de datos para saber si sí existe 
  previamente. En caso de que sí, podrá responder con sus credenciales completas (no sensibles). En caso de que un cliente intente autenticarse antes de haber generado un registro, el servidor no lo encontrará en la base y no habrá 
  credenciales por devolverle.
    
- Passport: Generador de estrategias de autenticación y autorización, para mantener un código limpio, estructurado y altamente configurable. Se puede utilizar y configurar múltiples estrategias de autenticación y autorización con passport  
    ✓ Passport local siempre requerirá dos cosas: username y password. Si passport no encuentra alguno de estos dos elementos, devolverá un error y no permitirá proceder con la estrategia
    ✓ Podemos cambiar el campo “username” para que tome el campo que nosotros queramos tomar como identificador, en este caso a nosotros no nos interesa nuestro username, realmente nos interesa el correo electrónico, así que podemos 
      alterarlo con {usernameField: ‘valor’}
    ✓ Passport utiliza un callback “done”, el cual se resuelve de la siguiente manera:
      ○ El primer parámetro de done es el error, si pasamos done(null) indicamos que no hay error.
      ○ El segundo parámetro debe ser el usuario generado, por lo tanto, para devolver un usuario, hacemos done(null, user).
      ○ Si pasamos done(null, false) indicamos que no hay error, pero el usuario no estará disponible.
    ✓ Cada estrategia que queramos configurar en passport es un middleware por sí solo, así que utilizaremos el elemento passport.use() para configurar diferentes middlewares/estrategias

  > Serializar y deserializar: Estas funciones permiten a Passport.js manejar la información del usuario durante el proceso de autenticación, serializando y deserializando los usuarios para almacenar y recuperar información de la sesión. 
    Permiten que la aplicación web gestione la autenticación de usuarios y recuerde la identidad del usuario autenticado entre las solicitudes HTTP.
    ~ Serializar (Serialize): significa convertir el objeto de usuario en una forma que pueda ser almacenada y posteriormente recuperada. Esencialmente, esto implica tomar los datos de usuario relevantes (como el ID de usuario) y 
      convertirlos en una representación que pueda ser almacenada, generalmente en una cookie de sesión o en una base de datos. Durante el proceso de serialización, Passport.js guarda el identificador único del usuario en la sesión del 
      usuario actual. Esto permite que la aplicación recuerde que el usuario está autenticado entre las solicitudes, incluso cuando las solicitudes individuales HTTP son independientes entre sí.
      En resumen, la serialización en Passport.js proporciona una forma de "recordar" la identidad del usuario autenticado entre las solicitudes HTTP.
      
    ~ Deserializar (Deserialize): Significa tomar la identificación del usuario que se almacenó durante la serialización y utilizarla para obtener los datos de usuario completos y autenticados.
      Durante el proceso de deserialización, Passport.js recupera los datos del usuario basados en el identificador almacenado en la sesión y los proporciona a la aplicación para que pueda realizar operaciones con el usuario autenticado, 
      como mostrar su perfil, permitirle acceder a recursos protegidos, etc. 
      En resumen, la deserialización en Passport.js permite a la aplicación recuperar los datos del usuario completo y autenticado a partir del identificador almacenado durante la serialización.
      
- JsonWebToken (JWT): Es un estándar que soluciona el problema de consultas y escalabilidad que presenta session. Este se basa en encriptar la información del usuario en un token que se guardará del lado del cliente, y el cliente lo enviará 
    al servidor en cada consulta, para poder desencriptar y obtener la información de usuario interna.
    Es mecanismo para poder propagar entre dos partes, y de forma segura, la identidad de un determinado usuario, además con una serie de claims o privilegios. Estos privilegios están codificados en objetos de tipo JSON, que se incrustan 
    dentro de del payload o cuerpo de un mensaje que va firmado digitalmente. Un token tres partes:
    ~ Header: encabezado dónde se indica, al menos, el algoritmo y el tipo de token, que en el caso del ejemplo anterior era el algoritmo HS256 y un token JWT.
    ~ Payload: donde aparecen los datos de usuario y privilegios, así como toda la información que queramos añadir, todos los datos que creamos convenientes. (tanto el Header como el Payload son texto plano que se codificara, pero No se 
      encriptara)
    ~ Signature: una firma que nos permite verificar si el token es válido, y aquí es donde radica el quid de la cuestión, ya que si estamos tratando de hacer una comunicación segura entre partes y hemos visto que podemos coger cualquier 
      token y ver su contenido con una herramienta sencilla. This is typically a hash of the header and payload sections of the JWT. The algorithm which is used to create the signature is the same algorithm mentioned in the header section of 
      the JWT. Signature is used to validate that the JWT token wasn’t modified or changed during transit. It can also be used to validate the sender. The header and Payload section of the JWT is always Base64 encoded.
      
    Es una implementación sin estado para poder mantener el ciclo de vida de la sesión de un usuario, sin el almacenamiento que este implica. Funciona de una manera diferente en session:
      ✓ El servidor generará un token con la información del usuario y la enviará al navegador.
      ✓ El navegador (front) almacenará dicho token y procederá a enviarlo en cada request por medio de los headers.
      ✓ El servidor recibe las peticiones, busca el token de jwt en los headers. Si lo encuentra, podrá proceder, si no, entonces requerirá autenticación nuevamente.
   
   La necesidad de almacenar las sesiones de lado del servidor o de una base de datos genera conflictos:
     ✓  Almacenamiento innecesario: Almacenar por miles, cientos de miles, o millones de usuarios, puede ser problemático a nivel almacenamiento.
     ✓ Tráfico saturado: Al vivir en una base de datos, session debe conectar con ella siempre que haya que consultar una sesión. Puede implicar detalles de rendimiento o requerir particiones de más. 
   
   JWT delega responsabilidad a cada cliente: Para aligerar el peso de la operación, el servidor puede otorgar el token de acceso al cliente y éste almacenarlo dentro del navegador en una cookie . Así, el cliente tiene la responsabilidad de 
   enviar sus credenciales con los datos de la sesión a manera de stateless. El servidor solo necesita descifrar el token para poder acceder a las credenciales del usuario . Esto le permite al servidor ser más ágil.
   
  > Working principle: When a user logs in or attempts to access a protected resource, the server generates a JWT after successful authentication. The client then stores this token, usually in local storage or a cookie. For every subsequent 
    request that requires authentication, the client sends the JWT in the request headers. The server validates the token by checking the signature and decoding the payload to ensure the user’s authenticity and authorization.
    
  > Secret key: The secret key is combined with the header and the payload to create a unique hash. You are only able to verify this hash if you have the secret key. Secret key used for signing and verifying JWTs. It must be replaced with a 
   strong secret key in production 
   
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$        

                                                                                                                   Process & Child Process
                                                                                                                   
- Sobre los entornos: Para que un código esté listo para llegar al cliente, es necesario que pase por diferentes fases.
  Sin embargo, para que estas fases se encuentren aisladas de las otras fases (no queremos que la fase de desarrollo tenga datos de producción, o que haya datos de producción en staging), necesitaremos crear entornos específicos para estas 
  fases. Nuestras variables cambiarán según el entorno.
  El primer uso radica en que una variable cambie según el entorno donde se esté corriendo, esto permite que pueda apuntar a una base de datos prueba o a una base de datos productiva con sólo cambiar el apuntador de dónde se está corriendo.
  Otro factor importante es el factor seguridad. Con las variables de entorno podemos ocultar la información sensible de nuestro código, como credenciales, claves de acceso, tokens, secrets, etc.                                                                                                                   
                                                                                                                   
- process: Cada vez que corremos un proceso en nodejs, éste genera un objeto llamado process, el cual contiene información referente a todo lo implicado con el proceso, cosas como:
    ✓ Uso de memoria 
    ✓ Id del proceso en el sistema operativo 
    ✓ En qué sistema operativo o plataforma está corriendo
    ✓ En qué entorno está corriendo. 
    ✓ Qué argumentos tiene el entorno.

 > Algunos elementos importantes de process
    ✓ process.cwd() : Directorio actual del proceso.
    ✓ process.pid : id del proceso en el sistema
    ✓ process.MemoryUsage() :
    ✓ process.env : Accede al objeto del entorno actual
    ✓ process.argv : Muestra los argumentos pasados por CLI (Los argumentos permiten iniciar la ejecución de un programa a partir de ciertos elementos iniciales)
    ✓ process.version : Muestra la versión del proceso (node en este caso)
    ✓ process.on() : Permite setear un listener de evento. Permitirá poner a nuestro proceso principal a la escucha de algún evento para poder ejecutar alguna acción en caso de que algo ocurra. (Listeners)
      ~ process.on('exit'); //Para ejecutar un código justo antes de la finalización del proceso.
      ~ process.on("warning"); //The 'warning' event is emitted whenever Node.js emits a process warning. A process warning is similar to an error in that it describes exceptional conditions that are being brought to the user's attention.
      ~ process.on('message'); //para poder comunicarse con otro proceso      

      ~ process.on("beforeExit"); //This event is emitted when node empties its event loop and has nothing else to schedule. Normally, the node exits when there is no work scheduled, but a listener for 'beforeExit' can make asynchronous 
        calls, and cause the node to continue.
        
      ~ process.on("rejectionHandled"); //The 'rejectionHandled' event is emitted whenever a Promise has been rejected and an error handler was attached to it (using promise.catch(), for example) later than one turn of the Node.js event 
        loop. The Promise object would have previously been emitted in an 'unhandledRejection' event, but during the course of processing gained a rejection handler.

      ~ process.on('uncaughtException'); It is emitted when an uncaught JavaScript exception bubbles all the way back to the event loop. By default, Node.js handles 
        such exceptions by printing the stack trace to stderr and exiting with code 1, overriding any previously set process.exitCode. Adding a handler for the 'uncaughtException' event overrides this default behavior. Alternatively, change 
        the process.exitCode in the 'uncaughtException' handler which will result in the process exiting with the provided exit code. Otherwise, in the presence of such handler the process will exit with 0.
        Para atrapar alguna excepción que no haya sido considerada en algún catch.
        
      ~ process.on("unhandledRejection"); //The 'unhandledRejection' event is emitted whenever a Promise is rejected and no error handler is attached to the promise within a turn of the event loop. When programming with Promises, exceptions 
        are encapsulated as "rejected promises". Rejections can be caught and handled using promise.catch() and are propagated through a Promise chain. The 'unhandledRejection' event is useful for detecting and keeping track of promises that 
        were rejected whose rejections have not yet been handled.               

    ✓ process.exit() : Permite salir del proceso. Cuando ejecutamos una salida con process.exit() como argumento, podemos enviar un código que sirve como identificador para el desarrollador sobre la razón de la salida
      Hay que conocer los códigos de salida para aber cómo utilizarlos. También podemos rear nuestros propios códigos. Algunos de los códigos importantes son:
        0 : proceso finalizado normalmente. 
        1 : proceso finalizado por excepción fatal 
        5 : Error fatal del motor V8. 
        9 : Para argumentos inválidos al momento de la ejecución.
     
 > arguments (commander): Commander es una librería para el manejo de argumentos. Permite realizar funciones como:
    ✓ Convertir flags directamente en booleanos
    ✓ Limitar sólo las flags configuradas (cualquier otra impide el procesamiento del programa)
    ✓ Colocar argumentos predeterminados.
      
- Child process: Single-threaded, non-blocking performance in Node.js works great for a single process. But eventually, one process in one CPU is not going to be enough to handle the increasing workload of your application. No matter how 
  powerful your server may be, a single thread can only support a limited load. The fact that Node.js runs in a single thread does not mean that we can’t take advantage of multiple processes and, of course, multiple machines as well.
  Using multiple processes is the best way to scale a Node application. Node.js is designed for building distributed applications with many nodes. This is why it’s named Node. Scalability is baked into the platform and it’s not something you 
  start thinking about later in the lifetime of an application.
  
  We can easily spin a child process using Node’s child_process module and those child processes can easily communicate with each other with a messaging system. The child_process module enables us to access Operating System functionalities 
  by running any system command inside a, well, child process. We can control that child process input stream, and listen to its output stream. We can also control the arguments to be passed to the underlying OS command, and we can do 
  whatever we want with that command’s output. We can, for example, pipe the output of one command as the input to another as all inputs and outputs of these commands can be presented to us using Node.js streams.

  Existen casos en los que un proceso de node necesitará crear otro proceso para poder resolver una función de gran complejidad. Algunas operaciones requieren mucho procesamiento, como:
    ✓ Lectura de archivos enormes
    ✓ Consultas a bases muy complejas 
  Por lo que, para no bloquear las tareas actuales de, un servidor, por ejemplo, ocupamos separar esa tarea en otro subproceso.
  Existen diferentes formas para que un proceso de node pueda ejecutar otro proceso, hay cuatro operadores que pueden ser utilizados y manipulados de diferentes formas
    --> https://www.freecodecamp.org/news/node-js-child-processes-everything-you-need-to-know-e69498fe970a/
   
    > fork(): The fork function is a variation of the spawn function for spawning node processes. The biggest difference between spawn and fork is that a communication channel is established to the child process when using fork, so we 
      can use the send function on the forked process along with the global process object itself to exchange messages between the parent and forked processes. We do this through the EventEmitter module interface.
      Se utiliza para ejecutar scripts Node.js en procesos secundarios y comunicarse con ellos.
          
    > spawn(): The spawn function launches a command in a new process and we can use it to pass that command any arguments. For example, here’s code to spawn a new process that will execute the pwd command.
      Esta función se utiliza para ejecutar un comando en un nuevo proceso. Permite especificar el comando a ejecutar y los argumentos que se le pasarán. También proporciona una interfaz para interactuar con la entrada, salida y 
      error estándar del proceso secundario en tiempo real. 
      Se utiliza para ejecutar comandos del sistema operativo.
   
    > exec(): It is used to test for the match in a string. If there is a match this method returns the first match else it returns NULL. Esta función se utiliza para ejecutar un comando en un subproceso con una shell. Es útil cuando se 
      necesita ejecutar comandos de shell con funcionalidades como expansión de comodines.
    
    > execFile(): 
    
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$        

                                                                                                                   Nestjs

- Definicion: Es un framework que permite crear Server Side Applications, de una manera eficiente y escalable. Está desarrollado con una base sólida de Typescript y brinda la posibilidad de seguir utilizando plain javascript. 
  Permite implementar paradigmas combinados de Programación Orientada a Objetos, Programación Funcional, y Programación Funcional reactiva. 
  Es un framework que está basado internamente en Express, y está pensado principalmente para construir aplicaciones monolíticas y microservicios.
  
- Instalación y primer proyecto: npm i -g @nestjs/cli  --> nest new <nombre de proyecto>
- Creacion de un modulo: nest g resource <nombre del modulo>    
        
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$        

                                                                                                                   Arquitectura de capas

- Definicion de aquitectura de capas: Es un patrón de diseño donde los módulos contemplados dentro de nuestro aplicativo son separados por “capas”. El nombre “capa” hace referencia a cada rol que debe cumplirse dentro de todo el aplicativo.                                                                                                                   

  > Responsabilidades: Cuando trabajamos con capas, entendemos que cada archivo debe cumplir una función específica, permitiendo así que, si llegase a ocurrir algún “error” o si llegase a requerirse modificación en algún punto, tengamos más 
    claro dónde debemos atacar esos cambios.
  > Capas base: En un sistema que trabaje con este modelo, es necesario contar con tres capas base:
     ✓ Capa de Modelo o Persistencia: Esta capa tiene por principal objetivo la conexión directa con el modelo de persistencia a trabajar, es decir, debe saber conectar con la persistencia en memoria, en archivos o en bases de datos. Todo 
       dependendiendo de cómo haya sido programada la capa. La capa de persistencia no debería realizar validaciones ni operaciones más allá del CRUD que corresponde a una capa de persistencia. Para modelos más complejos como Persistencias 
       en bases de datos, también es posible configurar operaciones transaccionales y Agregaciones en este mismo punto. 
     ✓ Capa de Vista o Renderización: La capa de renderizado o Vista, como indica su nombre, sólo tiene la función de tomar datos para poder ser renderizados. Esta capa es una de las más subjetivas en la arquitectura, pues si bien TODOS los 
       modelos requieren renderizar contenido, se hace de maneras muy diferentes. Renderizado, según sea el enfoque del equipo, también puede acceder a Persistencia sin necesidad de pasar por negocio, siempre y cuando ésta tenga como fin 
       único el de mostrar la información correspondiente. En ocasiones, también se suele contemplar la capa de renderizado fuera de la arquitectura interna y usar algún aplicativo externo (como enviar la info a React para que él la 
       renderice, que es lo más habitual).
     ✓ Capa de Controlador o Negocio: Esta capa tiene por principal objetivo la conexión directa con el modelo de persistencia a trabajar, es decir, debe saber conectar con la persistencia en memoria, en archivos o en bases de datos. Todo 
       dependendiendo de cómo haya sido programada la capa. La capa de persistencia no debería realizar validaciones ni operaciones más allá del CRUD que corresponde a una capa de persistencia. Para modelos más complejos como Persistencias 
       en bases de datos, también es posible configurar operaciones transaccionales y Agregaciones en este mismo punto. 
    Sin estas tres capas, el modelo se volvería inconsistente y la comunicación entre los módulos sería débil y generaría muchos problemas.
  > Capa de routing:  La capa de routing contendrá todos los archivos de tipo “router” que, como estamos ya acostumbrados, es una capa basada en redireccionamientos hacia puntos específicos de nuestra API. Actualmente, con el uso de motores 
    de plantillas, nuestra capa de routing está estrechamente conectada con la capa derenderización (al utilizar un views router). Sin esta capa, todas nuestras rutas de todas nuestras entidades se encontrarían en un mismo archivo, 
    complicando la lectura del código posteriormente.
  > Capa de servicio: La capa de servicios es una capa intermedia entre el controlador y la persistencia, en esencia, un servicio tiene la capacidad de servir como “tunel” de conexión, para que el controlador pueda acceder de manera más 
    homologada a la persistencia. Contar con una capa de servicio impide que los accesos a persistencia se hagan descontroladamente, con argumentos erróneos, etc. Además, son el punto clave para aplicar un patrón repository. No confundir una 
    capa de servicio con la capa de negocio, solo es un punto intermedio de conexión.

- Analisis del flujo y capas del proyecto: En ella se deben seguir los pasos adecuados para una mejor actitectura. Los cuales son:
  > Inicio: capa de vista, presentación o renderizado: Como es de esperarse, todo comienza desde el cliente, cuando este carga una página, aprieta un botón o desea buscar un dato, está haciendo una petición al servidor. Para ello, desde esta 
    capa se hace un “consumo”, el cual hará una operación de solicitud para obtener los datos.
  > Primer contacto (capa de ruteo): La petición tuvo que realizarse a partir de un endpoint, el cual entra a la capa de ruteo y designa cuál de todas las rutas corresponden a la acción que desea realizar el cliente.
  > Segundo contacto (capa de controlador): Cada ruta está relacionada con algún método o función de un controlador, así, cuando el router reconoce adónde está apuntando el cliente, sabe llevarlo a la función adecuada.
  > Tercer contacto (Capa de Servicio): Para poder obtener, un grupo de usuarios, la función perteneciente a estos usuarios requerirá acceder a un punto intermedio entre el controlador y entre la capa de persistencia para obtener la info.
  > Cuarto contacto (Capa de Persistencia): El punto intermedio mencionado arriba sabe que debe acceder a usuarios, el detalle es ¿de qué persistencia? ¿Memoria, archivos, base de datos? El servicio sabrá a qué persistencia conectar y 
    obtendrá los datos
  > Regreso (vuelta de datos y envío al cliente): Una vez obtenidos los datos a partir de la persistencia, el controlador termina de procesarlos y puede finalmente enviarlos al cliente para terminar el procesamiento de esa petición.
    

                                                                                                                   Patrones de diseño reconocidos en Expressjs
                                                                                                                   
- Cadena de responsabilidades: Permite que, cuando algún elemento envía información (sender) y existe alguien que lo reciba (receiver), a esa petición puedan recibirla y procesarla múltiples objetos (o funciones). Esto permite tener un mejor 
  control de la petición, agregar filtros y reenviar el objeto con sus respectivas alteraciones.   
  Express popularizó enormemente el concepto de un Middleware, que al final es una variante de la inyección de dependencias, donde al recibir un request, éste puede pasar por diferentes lógicas en cada middleware, al final, un middleware 
  responde para recibirse por otro middleware, y así sucesivamente hasta llegar al endpoint principal.
  
- Decorador: Permite mantener un objeto inicial genérico para poder procesar información, pero al ser utilizado éste está abierto a ser transformado a lo largo del flujo del proceso. De no querer que un objeto tenga añadiduras nuevas, 
  podemos congelar el objeto con “Object.freeze()”, sin embargo, rompería con el patrón decorador al no permitir que se le cambie.
  Cuando recibimos un request, el objeto request está predefinido con ciertas propiedades, sin embargo, podemos procesar n middlewares para transformar el request. Al usar multer, por ejemplo, a nuestro endpoint llega una propiedad req.file 
  o req.files, cosa que no teníamos antes del middleware.
  
- Proxy: También conocido como Proxy routing o simplemente Routing pattern, implica tener un sustituto (surrogate), el cual reciba una petición y controlar el acceso hacia otro objeto (subject). El sustituto recibirá todas las peticiones, 
  para después corroborar a quién debería corresponder dicha petición y enviársela. El sustituto y el objeto final deben contar con la misma interfaz. Cuando creamos un nuevo router en la aplicación principal de Express, y conectamos el 
  middleware de router con app.use(), éste se convierte en un sustituto que definirá a cuál router redirigir la información. Es el patrón más común que se puede reconocer en Express, pues son los primeros pasos que damos al comenzar a usarlo

- Patrón MVC: Es un patrón que ya se ha platicado ampliamente en las últimas clases, éste consistiendo en la separación de capas de modelo (persistencia), Vista (presentación) y Controlador (Negocio). Recordemos que al final el objetivo es 
  mantener un flujo con actividades bien delegadas y así poder tener mejor control sobre el código.

- Singleton Pattern: Es un patrón utilizado para tener una instancia global a nivel aplicación. En ocasiones, se requiere que la aplicación tenga una única instancia de dicha clase (Por ejemplo, al abrir una conexión en base de datos). El 
  patrón singleton corrobora si ya existe una instancia de esta clase. En caso de que sí, devolverá la instancia, caso contrario creará la instancia.
  Singleton is a design pattern that ensures that a class has only one immutable instance. Said simply, the singleton pattern consists of an object that can't be copied or modified. It's often useful when we want to have some immutable
  single point of truth for our application.
  
- Null Object Design Pattern: This Pattern wraps up the null into its own object. Instead of having a null reference for some object, we wrap it into a NULL version of that object which will implement the same interface that of the object, 
  i.e. same methods and properties. The intent of a NULL OBJECT is to encapsulate the absence of an object by providing a substitutable alternative that offers suitable default do-nothing-behavior. In short, a design where “nothing will come 
  of nothing”. We can use this pattern whenever we have the NULL object returned or checked against before accessing the properties of the object. It has a kind of do-nothing behavior on its methods.

- Facade Design Pattern: Facade design pattern is a Structural design pattern that allows users to create a simple interface that hides the complex implementation details of the system making it easier to use. This pattern intends to create 
  a simplified and unified interface for a set of interfaces hiding the implementation details making it less complex to use. The components of the Facade design pattern include:
    > Subsystem: The Subsystem is a class or group of classes or interfaces that handles the entire complex logic and implementation.
    > Facade: The Facade is the class or object that serves as an entry point to the Subsystem’s implementation hiding the complex implementation details.
    > Client: The Client interacts with the simplified Interface provided by Facade to perform operations without knowing the internal implementation details.

- Builder Pattern: This pattern is used to create objects in "steps". Normally we will have functions or methods that add certain properties or methods to our object. The cool thing about this pattern is that we separate the creation of 
  properties and methods into different entities. If we had a class or a factory function, the object we instantiate will always have all the properties and methods declared in that class/factory. But using the builder pattern, we can create 
  an object and apply to it only the "steps" we need, which is a more flexible approach.

- Command Pattern: With the Command Pattern, we can decouple objects that execute a certain task from the object that calls the method. The Command Pattern is a behavioral design pattern that converts requests or simple operations into 
  objects. The key idea here is that it encapsulates a request as an object, thereby letting us parameterize clients with queues, requests, operations, and also allows us to support undoable operations.
  The essence of this pattern involves three main components:
   > The Command: This is an interface that specifies how to carry out a given operation.
   > The Invoker: This is a component that uses the command to carry out a given operation.
   > The Receiver: This is the component that knows how to perform the operations associated with the command.
   
- Prototype Pattern: The Prototype pattern allows you to create an object using another object as a blueprint, inheriting its properties and methods. It is a useful way to share properties among many objects of the same type. The prototype 
  is an object that’s native to JavaScript, and can be accessed by objects through the prototype chain. In our applications, we often have to create many objects of the same type. A useful way of doing this is by creating multiple instances 
  of an ES6 class.
  
- Service: Es un archivo que va a contener todos los metodos que podemos llamar desde cualquier parte de la aplicacion.

- Factory Method Pattern: The Factory method pattern provides an interface for creating objects that can be modified after creation. The cool thing about this is that the logic for creating our objects is centralized in a single place, 
  simplifying and better organizing our code. This pattern is used a lot and can also be implemented in two different ways, via classes or factory functions (functions that return an object).
  
- Abstract Factory Pattern: This pattern allows us to produce families of related objects without specifying concrete classes. It's useful in situations where we need to create objects that share only some properties and methods.
  The way it works is by presenting an abstract factory the client interacts with. That abstract factory calls the corresponding concrete factory given the corresponding logic. And that concrete factory is the one that returns the end 
  object. Basically it just adds an abstraction layer over the factory method pattern, so that we can create many different types of objects, but still interact with a single factory function or class.
  
  
                                                                                                                   Arquitectura del servidor: Persistencia
                                                                                                                   
- Memoria: La información persiste sólo durante el ciclo de vida del programa, si se reinicia, la información desaparece.
- Archivos: La información se guarda en un fichero que permite persistir la información, aun cuando el programa se reinicie o apague.
- Base de datos: Permite que no solo se pueda almacenar información, sino también facilita la aplicación de un CRUD de manera rápida y segura. Es la persistencia por excelencia.

- DAO: Se encargará de conectar con nuestra fuente de datos según la hayamos programado, habrá DAOs programados para hacer CRUD en memoria, DAOs para hacer CRUD en archivos, etc. Así, en la lógica de negocio sólo se necesita importar el DAO 
  a trabajar y utilizarlo. Si en algún momento necesitamos cambiar de persistencia, bastará con cambiar el DAO

- El patrón DAO (persistencia aislada): consiste en separar la lógica de acceso a la fuente de datos en un archivo. Éste contará con métodos homologados de manera que, si en algún momento necesitamos cambiar el acceso a los datos, el DAO de 
  la nueva fuente de datos tenga exactamente el mismo nombre de métodos que el anterior, evitando así que haya conflictos al acceder a la información. Así, podemos tener un MemoryDAO, un fileDAO, un databaseDAO según sea el caso, e
  intercambiarlos sin problema
  
- Patrón Factory: La idea del patrón Factory, es basarse en una variable de entorno o configuración por argumentos, la cual tomará para decidir qué tipo de persistencia manejar. Esta “Fábrica” se encargará de devolver sólo el DAO que 
  necesitemos acorde con lo solicitado en el entorno o los argumentos. 
  
- Patron repository: 

- Patron service: 

- Data Transfer Object: DTOs or Data Transfer Objects are objects that carry data between processes in order to reduce the number of methods calls. The pattern’s main purpose is to reduce roundtrips to the server by batching up multiple 
  parameters in a single call. This reduces the network overhead in such remote operations. Another benefit is the encapsulation of the serialization’s logic (the mechanism that translates the object structure and data to a specific format 
  that can be stored and transferred). It provides a single point of change in the serialization nuances. It also decouples the domain models from the presentation layer, allowing both to change independently.


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$        


                                                                                                                   Data Modeling
                                                                                                                   
- Data Modeling: Data modeling refers to the organization of data within a database and the links between related entities. Data in MongoDB has a flexible schema model, which means: 
    + Documents within a single collection are not required to have the same set of fields. 
    + A field's data type can differ between documents within a collection. 
  Generally, documents in a collection share a similar structure. To ensure consistency in your data model, you can create schema validation rules.
  
  > Use Cases: The flexible data model lets you organize your data to match your application's needs. MD is a document database, meaning you can embed related data in object and array fields. A flexible schema is useful according to:
     + Your company tracks which department each employee works in. You can embed department information inside of the employee collection to return relevant information in a single query.
     + Your e-commerce application shows the five most recent reviews when displaying a product. You can store the recent reviews in the same collection as the product data, and store older reviews in a separate collection because the older 
       reviews are not accessed as frequently.
     + Your clothing store needs to create a single-page application for a product catalog. Different products have different attributes, and therefore use different document fields. You can store all of the products in the same collection.
  
  > Link Related Data: When you design your data model in MongoDB, consider the structure of your documents and the ways your application uses data from related entities. To link related data, you can either: 
    + Embed related data within a single document.
    + Store related data in a separate collection and access it with a  reference.

- Denormalization: Denormalization is used to combine multiple table data into one so that it can be queried quickly. It is a process of storing the join of higher normal form relations in the form of base relation that is in a lower normal 
  form. The primary goal of denormalization is to achieve the faster execution of the queries.
  In the process of denormalization, the data is integrated into the same database. Denormalization is mainly used where joins are expensive and queries are executed on the table very frequently. However, there is a drawback of 
  denormalization, that is, a small wastage of memory.

- Normalization: Normalization is used to remove redundant data from the database and to store non-redundant and consistent data into it. It is a process of converting an unnormalized table into a normalized table. Database normalization is 
  an important process because a poorly designed database table is inconsistent and may create issues while performing operations like insertion, deletion, updating, etc. 
  The process of Normalization involves resolution of database anomalies, elimination of data redundancy, data dependency, isolation of data, and data consistency. Normalization in databases provides a formal framework to analyze the 
  relations based on the key attributes and their functional dependencies. It reduces the requirements of restructuring of tables.
    > Child referencing: The Child References pattern stores each tree node in a document; in addition to the tree node, document stores in an array the id(s) of the node's children. Each node contains a reference array to its children
    > Parent referencing: The Parent References pattern stores each tree node in a document; in addition to the tree node, the document stores the ID of the node's parent. Each node contains a reference to its parent.
    
- Difference between Normalization and Denormalization: The following table highlights the important differences between Normalization and Denormalization
  > Normalization
    + Implementation: Normalization is used to remove redundant data from the database and to store non-redundant and consistent data into it.	
    + Focus: Normalization mainly focuses on clearing the database from unused data and to reduce the data redundancy and inconsistency.	
    + Number of Tables: During Normalization, data is reduced, so there will be a decrease in the number of tables.	
    + Memory consumption: Normalization uses optimized memory and hence faster in performance.	
    + Data integrity: Normalization maintains data integrity, i.e., any addition or deletion of data from the table will not create any mismatch in the relationship of the tables.	
    + Where to use: Normalization is generally used where a number of insert/update/delete operations are performed and joins of those tables are not expensive.	
  
  > Denormalization
    + Implementation: Denormalization is the process of adding some redundant data to a database that has been normalized, so as to improve the read performance (execution time) of the database
    + Focus: The real goal of denormalization is to achieve the faster execution of the queries by introducing redundancy.
    + Number of Tables: During Denormalization, data is integrated into the same database and hence there will be an increase in the number of tables.
    + Memory consumption: Denormalization introduces some sort of wastage of memory.
    + Data integrity: Denormalization does not maintain any data integrity.
    + Where to use: Denormalization is used where joins are expensive and frequent queries are executed on the tables.

- Embedded Documents: Embedded documents store related data in a single document structure. A document can contain arrays and sub-documents with related data. These denormalized data models allow applications to retrieve related data in a 
  single database operation. For many use cases in MongoDB, the denormalized data model is optimal.
  Embedded documents are stored as children inside a parent document. This means they are all stored under one collection, and whenever you retrieve the parent document, you also retrieve all its embedded documents
  For example, if you had a user document, it may contain a list of embedded documents detailing that user’s addresses. In JSON format, it may look something like this:
    
        {
          "_id": 1,
          "name": "Ashley Peacock",
          "addresses": [
            {
              "address_line_1": "10 Downing Street",
              "address_line_2": "Westminster",
              "city": "London",
              "postal_code": "SW1A 2AA"
            },
            {
              "address_line_1": "221B Baker Street",
              "address_line_2": "Marylebone",
              "city": "London",
              "postal_code": "NW1 6XE"
            }
          ]
        }
     By storing our addresses as embedded documents, we’re only persisting a single document.
        
- References: References store relationships between data by including links, called references, from one document to another. For example, a customerId field in an orders collection indicates a reference to a document in a customers 
  collection. Applications can resolve these references to access the related data. Broadly, these are normalized data models.
  Unlike embedded documents, referenced documents are stored in a separate collection to their parent document. Therefore, it’s possible to retrieve the parent document without retrieving any of its referenced documents.

        // Stored in the user collection
        {
          "_id": 1,
          "name": "Ashley Peacock",
          "addresses": [
            1000,
            1001
          ]
        }
        // Stored in the address collection
        {
          "_id": 1000,
          "address_line_1": "10 Downing Street",
          "address_line_2": "Westminster",
          "city": "London",
          "postal_code": "SW1A 2AA"
        }
        // Stored in the address collection
        {
          "_id": 1001,
          "address_line_1": "221B Baker Street",
          "address_line_2": "Marylebone",
          "city": "London",
          "postal_code": "NW1 6XE"
        }
        
  In storing our addresses using references, we’re storing 3 separate documents. If we want to retrieve a user’s addresses along with the user, we must effectively run 2 queries: the first to retrieve the user, the second to retrieve 
  their addresses. This is because MongoDB, unlike SQL, has no performant concept of a join. It does provide a lookup operation, but it’s not typically performant enough to use in a real time production environment — both in terms of 
  speed and resources. Instead, we should look to better design our schemas to suit MongoDB, which is what we’ll cover next. 
  It’s worth noting we can choose how we model the relationship when using references. We can decide, as we have above, to store a list of references on the parent document. If the list of references is likely to become large, it’s 
  usually better to store the ID of the parent document (user in this case) in any related documents (in the address in this case). Otherwise, each time we add a new address, we have to update the user document to add the new reference.
     
- How To Choose Between Embedded Or Referenced Documents: Generally speaking, we should look to use embedded documents when both the parent document and its related documents are either read or written at the same time. Furthermore, we 
  should prioritise based on whether the collection is read or write heavy. For example, consider the following document:
        {
          "_id": 1,
          "name": "Ashley Peacock",
          "account_balance": 150
          "stocks": [
            {
              "code": "AMZN",
              "amount": "3",
              "value": "1478.22"
            }
          ],
          "orders": [
            {
              "order_id": 1,
              "order_value": 102.5,
              "order_items": [...]
            }
          ]
        }
        
  We have two embedded documents: stocks and orders. Should they be embedded, though? To answer that question, we need a little more context — here’s what the fictional stock trading application looks like in terms of how we interact with 
  our user collection: 
     + Once logged in, the user ID is stored in the web session.
     + Stocks contain the stocks the user currently owns. They are shown on almost every page of the website, and must be retrieved from the database each time a page is rendered for compliance and accuracy reasons. Stocks are updated 
       infrequently when compared to how often they are read.
     + The account balance is also shown on every page.
     + Orders are only shown on the orders page, and only updated when an order is placed.
     
  In this case, I would store the stocks as embedded documents because whenever we render a page we need both the account balance and the list of stocks. If we stored them separately, we’d have to execute two separate queries — one to get 
  the user, another to get their stocks. Considering this data is shown on every page, we’d be doubling the number of queries per page load if we referenced them.
  Moving on to the orders, I would store these as referenced documents, as they are only used on specific pages. Furthermore, we can query for orders, and add new orders, simply by using the user ID stored in the web session — without 
  querying the user collection at all.
  A user could have 100’s of orders. If we stored them as embedded documents, the amount of data returned for the user query would grow significantly over time. Additionally, it would return a large amount of data that isn’t used on the 
  majority of the website. To add a new order, we would need to read the entire user document, append the new order, and then re-write the entire document.
  Using referenced documents however, we can simply insert a new document into the orders collection, tied to the user ID, and we don’t have to read the user collection at all (or any other orders!).
